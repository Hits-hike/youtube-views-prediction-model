{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        만 19세 '연봉 1억' 친구와 레스토랑 브이로그\n",
       "1                               BBQ 신메뉴 '체고치' 순살 먹어봄\n",
       "2                                     구찌 라이톤이랑 시계 후기\n",
       "3                                엽기 로제떡볶이랑 허니 콤보 혼내줌\n",
       "4                                 어림도 없지 바로 마라탕 먹어버림\n",
       "                             ...                    \n",
       "101159                     '현실남매' 먹방하러 갔다가 진짜 싸웠습니다.\n",
       "101160    [직업체험] DJ예나 일일 매니저 (월디페/World DJ Festival)\n",
       "101161                           저의 슈퍼모델 친구들을 소개합니다.\n",
       "101162             '현실남매' 우리만 이런건가요? 남들이 이해 못하는 현실남매\n",
       "101163          유튜브 시작하기 \"일반인이 유튜브를 시작하면 가장 많이하는 고민\"\n",
       "Name: title, Length: 101164, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original = pd.read_csv(\"./pretest_data.csv\")\n",
    "data_original['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct1 = \"/-'.,#$\\'()*+-/:;<=>@[\\\\]^_`{|}~%\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "punct2 = \"!?|│\" #not remove\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\",\n",
    "                 \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\",\n",
    "                 \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"',\n",
    "                 '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta',\n",
    "                 '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-',\n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "\n",
    "def clean_punc(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    for p in punct1:\n",
    "        text = text.replace(p, f' ')\n",
    "    for p in punct2:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "        \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n",
    "    \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_clean_punc = []\n",
    "for title in data_original['title']:\n",
    "    data_clean_punc.append(clean_punc(title, punct, punct_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def clean_text(texts):\n",
    "    corpus = []\n",
    "    for i in range(0, len(texts)):\n",
    "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '', str(texts[i])) #remove punctuation\n",
    "        #review = re.sub(r'\\d+','', str(texts[i]))# remove number\n",
    "        review = review.lower() #lower case\n",
    "        review = re.sub(r'\\s+', ' ', review) #remove extra space\n",
    "        #review = re.sub(r'<[^>]+>','',review) #remove Html tags\n",
    "        review = re.sub(r'\\s+', ' ', review) #remove spaces\n",
    "        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n",
    "        review = re.sub(r'\\s+$', '', review) #remove space from the end\n",
    "        review = emoji.demojize(review)\n",
    "        corpus.append(review)\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_text = clean_text(data_clean_punc)\n",
    "data_clean_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
